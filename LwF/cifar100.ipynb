{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.training.supervised import LwF\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.datasets import CIFAR100\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceTime, EpochAccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "cudnn.enabled = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CIFAR100('../Dataset/CIFAR100', train=True, download=True)\n",
    "test_set = CIFAR100('../Dataset/CIFAR100', train=False, download=True)\n",
    "\n",
    "transforms_group = dict(\n",
    "       train=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       ),\n",
    "       eval=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       )\n",
    ")\n",
    "\n",
    "train_set = AvalancheDataset(train_set, transform_groups=transforms_group, initial_transform_group=\"train\")\n",
    "test_set = AvalancheDataset(test_set, transform_groups=transforms_group, initial_transform_group=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 100\n",
    "incremental = 10\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=False,\n",
    "                        seed=seed,\n",
    "                        shuffle=False\n",
    "                        )\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False, num_classes=num_class)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(project_name=\"CL-Test\", run_name=\"iCaRL-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LwF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 128\n",
    "eval_batch = 128\n",
    "epoch = 10\n",
    "lwf_alpha = [0, 0.5, 1.333, 2.25, 3.2]\n",
    "\n",
    "strategies = LwF(model, optimizer, criterion, alpha=lwf_alpha, temperature=1, train_epochs=epoch, device=device, train_mb_size=train_batch, eval_mb_size=eval_batch, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting experiment...\")\n",
    "results = []\n",
    "\n",
    "for experience in scenario.train_stream:\n",
    "    print(\"Start training on experience \", experience.current_experience)\n",
    "    strategies.train(experience)\n",
    "    print(\"End training on experience \", experience.current_experience)\n",
    "    print(\"Computing accuracy on the test set\")\n",
    "    results.append(strategies.eval(scenario.test_stream[:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('hspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7200c97f9580f269913cae0521a31c8c9bc2a022b66e7eee6f7caa3cb908faad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
